{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "MAX_PAGE_NUM=3\n",
    "with open('amazon_selenium.csv','w') as f:\n",
    "    f.write(\"username,title,date,comment,skillname,totalrating,avgrating\\n\")\n",
    "for i in range(1,MAX_PAGE_NUM+1):\n",
    "    page_num=i\n",
    "    print(page_num)\n",
    "    url='https://www.amazon.com/Voxion-Mutter-Nonsense/product-reviews/B086Q3LWW7/ref=cm_cr_getr_d_paging_btm_prev_1?ie=UTF8&reviewerType=all_reviews&pageNumber='+str(page_num)\n",
    "    browser = webdriver.Chrome(\"/Users/baongocdinh/downloads/chromedriver\" )\n",
    "    browser.get(url)\n",
    "    time.sleep(10)\n",
    "    html=browser.page_source\n",
    "    soup=BeautifulSoup(html, 'html.parser')\n",
    "    reviews=soup.find_all(\"div\",{\"data-hook\":\"review\"})\n",
    "    data=[]\n",
    "    for i in reviews:\n",
    "        username,title,date,comment,skillname,totalrating,avgrating='NA','NA','NA','NA','NA','NA','NA'\n",
    "        #username,title,date,comment='NA','NA','NA','NA'\n",
    "        usernamechunk=i.find('span',{'class':('a-profile-name')})\n",
    "        if usernamechunk:\n",
    "            username=usernamechunk.text.strip()\n",
    "        titlechunk=i.find('a',{'data-hook':('review-title')})\n",
    "        if titlechunk:\n",
    "            title=titlechunk.text.strip()\n",
    "            title=title.replace(\",\",\"\")\n",
    "        datechunk=i.find('span',{'data-hook':('review-date')})\n",
    "        if datechunk:\n",
    "            date=datechunk.text.strip()\n",
    "            date=date.replace(\",\",\"\")\n",
    "        commentchunk=i.find('span',{'data-hook':('review-body')})\n",
    "        if commentchunk:\n",
    "            comment=commentchunk.text.strip()\n",
    "            comment=comment.replace(\",\",\"\")\n",
    "        skillnamechunk=soup.find('a',{'data-hook':('product-link')})\n",
    "        if skillnamechunk:\n",
    "            skillname=skillnamechunk.text.strip()\n",
    "            skillname=skillname.replace(\",\",\"\")\n",
    "        avgratingchunk=soup.find('span',{'data-hook':('rating-out-of-text')})\n",
    "        if avgratingchunk:\n",
    "            avgrating=avgratingchunk.text.strip()\n",
    "            avgrating=avgrating.replace(\",\",\"\")\n",
    "        totalratingschunk=soup.find('span',{'class':('a-size-base a-color-secondary')})\n",
    "        if totalratingschunk:\n",
    "            totalrating=totalratingschunk.text.strip()\n",
    "            totalrating=totalrating.replace(\",\",\"\")\n",
    "            #data.append([username,title,date,comment,skillname,totalrating,avgrating])\n",
    "                #data.append([username,title,date,comment])\n",
    "            #num_page_item=len(reviews)\n",
    "            with open('amazon_selenium.csv','a') as f:\n",
    "                f.write(username+\",\"+title+\",\"+date+\",\"+comment+\",\"+skillname+\",\"+totalrating+\",\"+avgrating+\"\\n\")\n",
    "                #for i in range(num_page_item):\n",
    "                    #f.write(username+\",\"+title+\",\"+date+\",\"+comment+\"\\n\")\n",
    "        #df = pd.DataFrame({\"username\": username, \"title\": title, \"date\": date, \"comment\": comment})\n",
    "        #df.to_csv(\"amazon_selenium.csv\")\n",
    "    browser.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = webdriver.Chrome(\"/Users/baongocdinh/downloads/chromedriver\" )\n",
    "url='https://www.amazon.com/Voxion-Mutter-Nonsense/product-reviews/B086Q3LWW7/ref=cm_cr_getr_d_paging_btm_prev_1?ie=UTF8&reviewerType=all_reviews&pageNumber='+page_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.get(url)\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "element=browser.find_element_by_xpath(\"//*[@id='cm_cr-pagination_bar']/ul/li[2]/a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "element.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "element=browser.find_element_by_xpath(\"//*[@id='cm_cr-pagination_bar']/ul/li[2]/a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "element.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "html=browser.page_source\n",
    "soup=BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-92-163d5027fba3>, line 29)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-92-163d5027fba3>\"\u001b[0;36m, line \u001b[0;32m29\u001b[0m\n\u001b[0;31m    mark_complete.click()\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    try:\n",
    "        reviews=soup.find_all(\"div\",{\"data-hook\":\"review\"})\n",
    "        for i in reviews:\n",
    "            username,title,date,comment,skillname,totalrating,avgrating='NA','NA','NA','NA','NA','NA','NA'\n",
    "            usernamechunk=i.find('span',{'class':('a-profile-name')})\n",
    "            if usernamechunk:\n",
    "                username=usernamechunk.text.strip()\n",
    "            titlechunk=i.find('a',{'data-hook':('review-title')})\n",
    "            if titlechunk:\n",
    "                title=titlechunk.text.strip()\n",
    "            datechunk=i.find('span',{'data-hook':('review-date')})\n",
    "            if datechunk:\n",
    "                date=datechunk.text.strip()\n",
    "            commentchunk=i.find('span',{'data-hook':('review-body')})\n",
    "            if commentchunk:\n",
    "                comment=commentchunk.text.strip()   \n",
    "            skillnamechunk=soup.find('a',{'data-hook':('product-link')})\n",
    "            if skillnamechunk:\n",
    "                skillname=skillnamechunk.text.strip()\n",
    "            print(skillname)\n",
    "            avgratingchunk=soup.find('span',{'data-hook':('rating-out-of-text')})\n",
    "            if avgratingchunk:\n",
    "                avgrating=avgratingchunk.text.strip()\n",
    "            totalratingschunk=soup.find('span',{'class':('a-size-base a-color-secondary')})\n",
    "            if totalratingschunk:\n",
    "                totalrating=totalratingschunk.text.strip()\n",
    "            mark_complete=browser.find_element_by_xpath(\"//*[@id='cm_cr-pagination_bar']/ul/li[2]/a\")\n",
    "            mark_complete.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'40  customer ratings'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalrating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<span class=\"a-profile-name\">Valeria Araujo</span>,\n",
       " <span class=\"a-profile-name\">Beth</span>,\n",
       " <span class=\"a-profile-name\">Beth</span>,\n",
       " <span class=\"a-profile-name\">Amazon Customer</span>,\n",
       " <span class=\"a-profile-name\">Jeff Blakely</span>,\n",
       " <span class=\"a-profile-name\">JD</span>,\n",
       " <span class=\"a-profile-name\">Amazon Customer</span>,\n",
       " <span class=\"a-profile-name\">Amazon Customer</span>,\n",
       " <span class=\"a-profile-name\">Bruce</span>,\n",
       " <span class=\"a-profile-name\">Joanne</span>,\n",
       " <span class=\"a-profile-name\">Sharon Ward</span>,\n",
       " <span class=\"a-profile-name\">Mark</span>]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/baongocdinh/downloads/tweets.txt','w',encoding='utf8') as fw:\n",
    "    for tweet in tweets:\n",
    "        \n",
    "        txt,retweets='NA','NA'\n",
    "        \n",
    "        try: \n",
    "            txt=tweet.find_element_by_css_selector(\"[class$=tweet-text]\").text\n",
    "        except: \n",
    "            print ('no text')     \n",
    "    \n",
    "        try:\n",
    "            retweetElement=tweet.find_element_by_css_selector(\"[class$=js-actionRetweet]\")\n",
    "            retweets=retweetElement.find_element_by_css_selector('[class=ProfileTweet-actionCountForPresentation]').text                                      \n",
    "        except:\n",
    "            print ('no retweets')\n",
    "    \n",
    "        fw.write(txt.replace('\\n',' ')+'\\t'+str(retweets)+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.close()        \n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
